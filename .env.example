# Configuración del servidor
NODE_ENV=development
PORT=3000
BASE_URL=http://localhost:3000

# Configuración del modelo LLM
# Hugging Face API (gratuita con límites)
HUGGING_FACE_API_KEY=your_hugging_face_api_key_here
LLM_BASE_URL=https://api-inference.huggingface.co
LLM_MODEL=microsoft/DialoGPT-medium

# Alternativas de modelos LLM gratuitos:
# LLM_MODEL=facebook/blenderbot-400M-distill
# LLM_MODEL=microsoft/DialoGPT-small
# LLM_MODEL=facebook/blenderbot_small-90M

# Para usar con Ollama local (requiere instalación local)
# LLM_BASE_URL=http://localhost:11434
# LLM_MODEL=llama2

# Configuración de CORS (para producción)
ALLOWED_ORIGINS=http://localhost:3000,https://your-frontend-domain.com

# Configuración de rate limiting
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX=100
